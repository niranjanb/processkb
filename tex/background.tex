% !TEX root =  main.tex
\section{Background and Prior Work}

Much progress has been made on question answering involving simple facts~\cite{berant2013semantic,fader2014open,bordes2014open,reddy2014large}. 
This is in large part due to the availability of large scale curated relational knowledge bases such as Freebase, coupled with significant advances in automatic relation extraction~\cite{schmitz2012open,carlson2010toward,suchanek2007yago}. Similar advances in large scale inference-supporting knowledge is vital for making significant progress in reasoning-based QA tasks. 

Recently introduced tasks such as {\em MCTest} reading comprehension challenge~\cite{richardson2013mctest}, grade-level science exams~\cite{clark2015elementary}, and process comprehension tasks~\cite{berantSrikumar14} serve as excellent benchmarks for developing reasoning-based question answering systems. These tasks test the ability of the systems to interpret and reason about scenarios and situations.

PI's prior work on knowledge requirements analysis for grade-level science exams shows the need for deep inference supporting knowledge~\cite{chb2013:akbc,clark2014:akbc}.
Also PI's recent work on reasoning shows that even with advanced state-of-the-art reasoning techniques, shallow text-derived knowledge is ineffective due to lexical and syntactic variations in language~\cite{khot2015:emlnlp}. Scalable acquisition of deeper semantic knowledge is essential for effective reasoning in these tasks. 

In this work, we target extraction of semantic knowledge about physical, chemical, and other natural phenomena.
The goal is to derive knowledge that allows effective reasoning about scenarios involving these phenomena. 
Our central premise is that the entities involved in a process and the roles they play provide a powerful representation for reasoning and QA. 
Similar representations are shown to be useful for Open-domain factoid question answering~\cite{shen2007using,pizzato2008indexing}, 
and comprehension questions on process descriptions~\cite{berantSrikumar14}.

As preliminary work, we first analyzed the knowledge requirements for a set of questions from fourth grade science exams targeting around 150 processes. 
While a small collection of general purpose roles (e.g., Undergoer, Result, Enabler, Trigger) capture the key semantic elements for a 
majority of the processes~\cite{louvan2015:kcap}, we also find that a set of domain specific roles (e.g., Direction, Medium) are also critical. We propose to compose a representation that combines both general and domain specific roles. 



